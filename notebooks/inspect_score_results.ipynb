{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the DVC pipeline has been run. From the terminal, run:\n",
    "\n",
    "```\n",
    "dvc repro\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = pathlib.Path(\"data/scores/results.csv\")\n",
    "results_agg_file = pathlib.Path(\"data/scores/results_agg.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(results_file)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_cols = [\"auroc\",  \"lift_at_100\",  \"lift_at_num_errors\", \"auprc\",  \"ap_at_100\",  \"ap_at_num_errors\"]\n",
    "df_agg = df.groupby([\"aggregator\", \"aggregator_kwargs\"])[metrics_cols].agg([\"mean\"])\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do the aggregators do?\n",
    "\n",
    "Given a score $\\textbf{x} = (x_0, ... , x_K)$ for an example, where $K$ is the number of class labels, we have several methods to aggregate the $K$ scores into a single score. The most common methods are:\n",
    "\n",
    "## `amax`\n",
    "This selects the class label quality score with the highest value for each example.\n",
    "This is an optimistic measure of the quality of the model's predictions.\n",
    "\n",
    "## `amin`\n",
    "This selects the class label quality score with the lowest value for each example.\n",
    "This is a pessimistic measure of the quality of the model's predictions.\n",
    "\n",
    "## `mean`\n",
    "This selects the mean of the class label quality scores for each example.\n",
    "\n",
    "## `median`\n",
    "This selects the median of the class label quality scores for each example.\n",
    "\n",
    "## `softmin_pooling`\n",
    "Applies a softmin kernel to the class label quality scores for each example.\n",
    "\n",
    "The softmin-pooled score is given by:\n",
    "\n",
    "$$\n",
    "s = \\frac{ \\exp(-x_i/\\tau) x_i}{\\sum_{i=0}^K \\exp(-x_i/\\tau)}\n",
    "$$\n",
    "\n",
    "where $\\tau$ is a temperature parameter and \n",
    "\n",
    "## `log_transform_pooling`\n",
    "Takes the log of each class label quality score, scales them by a weight, displaces them by a bias, and then takes the mean of the resulting values.\n",
    "\n",
    "The log-pooled score is given by:\n",
    "\n",
    "$$\n",
    "s = \\frac{1}{K} \\sum_{i=0}^K \\left( w_i \\log(x_i + \\epsilon) + b_i \\right)\n",
    "$$\n",
    "\n",
    "where $\\textbf{w} = (w_0, ... , w_K)$ are the weights, $\\textbf{b} = (b_0, ... , b_K)$ are the biases, and $\\epsilon$ is a small constant (machine epsilon) used to prevent taking the log of zero.\n",
    "\n",
    "## `cumulative_average_ks`\n",
    "This computes the cumulative average of the bottom $k$ class label quality scores for each example, i.e. the average of the $k$ worst scores.\n",
    "\n",
    "## `simple_moving_average_ks`\n",
    "This takes a _simple_ moving average (SMA) with window size $k$ of the sorted class label quality scores for each example.\n",
    "The final score for each example is the mean of the moving averages.\n",
    "\n",
    "## `exponential_moving_average`\n",
    "This takes an _exponential_ moving average (EMA) of the sorted class label quality scores for each example with forgetting factor $\\alpha$.\n",
    "\n",
    "The EMA is calculated with:\n",
    "\n",
    "$$\n",
    "s_i = \\begin{cases}\n",
    "x_i & i = 0 \\\\\n",
    "\\alpha x_i + (1 - \\alpha) s_{i-1} & i > 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The final score for each example is $s_{K-1}$, i.e. the last value in the EMA sequence.\n",
    "\n",
    "## `weighted_cumulative_average`\n",
    "This computes cumulative averages $(s_1, s_2, ..., s_k)$ ($k \\leq K$) of the class label quality scores sorted in asceding ordder for each example, and then takes the weighted average of those values.\n",
    "\n",
    "The final score for each example is given by:\n",
    "\n",
    "$$\n",
    "s = \\sum_{i=0}^k f(i) s_i\n",
    "$$\n",
    "\n",
    "where $f(i)$ is a scalar weighting function.\n",
    "\n",
    "### Possible weighting functions\n",
    "The weighting function $f(i)$ can be one of the following:\n",
    "\n",
    "#### Simple mean\n",
    "This gives the unweighted mean of the cumulative averages:\n",
    "$$\n",
    "f(i) = \\frac{1}{k}\n",
    "$$\n",
    "\n",
    "#### Exponential decay\n",
    "Each rank is decayed with the exponential function:\n",
    "$$\n",
    "f(i) = \\exp(-i)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
